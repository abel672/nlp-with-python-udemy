{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Basics Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assessment we'll be using the short story [_An Occurrence at Owl Creek Bridge_](https://en.wikipedia.org/wiki/An_Occurrence_at_Owl_Creek_Bridge) by Ambrose Bierce (1890). <br>The story is in the public domain; the text file was obtained from [Project Gutenberg](https://www.gutenberg.org/ebooks/375.txt.utf-8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL to perform standard imports:\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Create a Doc object from the file `owlcreek.txt`**<br>\n",
    "> HINT: Use `with open('../TextFiles/owlcreek.txt') as f:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here:\n",
    "with open('../TextFiles/owlcreek.txt') as f:\n",
    "    doc = nlp(f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AN OCCURRENCE AT OWL CREEK BRIDGE\n",
       "\n",
       "by Ambrose Bierce\n",
       "\n",
       "I\n",
       "\n",
       "A man stood upon a railroad bridge in northern Alabama, looking down\n",
       "into the swift water twenty feet below.  "
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "# Run this cell to verify it worked:\n",
    "\n",
    "doc[:36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. How many tokens are contained in the file?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4833\n"
     ]
    }
   ],
   "source": [
    "print(len(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. How many sentences are contained in the file?**<br>HINT: You'll want to build a list first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sent for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Print the second sentence in the document**<br> HINT: Indexing starts at zero, and the title counts as the first sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A man stood upon a railroad bridge in northern Alabama, looking down\ninto the swift water twenty feet below.  \n"
     ]
    }
   ],
   "source": [
    "print(sentences[2].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5. For each token in the sentence above, print its `text`, `POS` tag, `dep` tag and `lemma`<br>\n",
    "CHALLENGE: Have values line up in columns in the print output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A DET det a\nman NOUN nsubj man\nstood VERB ROOT stand\nupon ADP prep upon\na DET det a\nrailroad NOUN compound railroad\nbridge NOUN pobj bridge\nin ADP prep in\nnorthern ADJ amod northern\nAlabama PROPN pobj Alabama\n, PUNCT punct ,\nlooking VERB advcl look\ndown ADV advmod down\n\n SPACE  \n\ninto ADP prep into\nthe DET det the\nswift ADJ amod swift\nwater NOUN pobj water\ntwenty NUM nummod twenty\nfeet NOUN npadvmod foot\nbelow ADV advmod below\n. PUNCT punct .\n  SPACE   \n"
     ]
    }
   ],
   "source": [
    "# NORMAL SOLUTION:\n",
    "for token in sentences[2]:\n",
    "    print(token.text, token.pos_, token.dep_, token.lemma_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A               DET   det        a              \nman             NOUN  nsubj      man            \nstood           VERB  ROOT       stand          \nupon            ADP   prep       upon           \na               DET   det        a              \nrailroad        NOUN  compound   railroad       \nbridge          NOUN  pobj       bridge         \nin              ADP   prep       in             \nnorthern        ADJ   amod       northern       \nAlabama         PROPN pobj       Alabama        \n,               PUNCT punct      ,              \nlooking         VERB  advcl      look           \ndown            ADV   advmod     down           \n\n               SPACE            \n              \ninto            ADP   prep       into           \nthe             DET   det        the            \nswift           ADJ   amod       swift          \nwater           NOUN  pobj       water          \ntwenty          NUM   nummod     twenty         \nfeet            NOUN  npadvmod   foot           \nbelow           ADV   advmod     below          \n.               PUNCT punct      .              \n                SPACE                           \n"
     ]
    }
   ],
   "source": [
    "# CHALLENGE SOLUTION:\n",
    "for token in sentences[2]:\n",
    "    print(f'{token.text:{15}} {token.pos_:{5}} {token.dep_:{10}} {token.lemma_:{15}}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Write a matcher called 'Swimming' that finds both occurrences of the phrase \"swimming vigorously\" in the text**<br>\n",
    "HINT: You should include an `'IS_SPACE': True` pattern between the two words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher library:\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pattern and add it to matcher:\n",
    "pattern = [{'LOWER':'swimming'}, {'IS_SPACE': True, 'OP': '*'}, {'LOWER':'vigorously'}]\n",
    "\n",
    "matcher.add('Swimming', None, pattern)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(12881893835109366681, 1274, 1277), (12881893835109366681, 3607, 3610)]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of matches called \"found_matches\" and print the list:\n",
    "found_matches = matcher(doc)\n",
    "\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Print the text surrounding each found match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surrounding_simple(start, end, doc):\n",
    "    print(doc[start-10:end+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surrounding_advanced(text, doc):\n",
    "    for match_id, start, end in text:\n",
    "        span = doc[start-10:end+10]\n",
    "        print(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " By diving I could evade the bullets and, swimming\nvigorously, reach the bank, take to the woods and\n"
     ]
    }
   ],
   "source": [
    "surrounding_simple(1274, 1277, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "saw all this over his shoulder; he was now swimming\nvigorously with the current.  His brain was as energetic\n"
     ]
    }
   ],
   "source": [
    "surrounding_simple(3607, 3610, doc)"
   ]
  },
  {
   "source": [
    "### Extra Credit:\n",
    "### Print the sentence that contains each found match"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "By diving I could evade the bullets and, swimming\nvigorously, reach the bank, take to the woods and get away home.  \n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    if found_matches[0][1] < sentence.end:\n",
    "        print(sentence)\n",
    "        break\n",
    "\n",
    "# each sentence has a start and end\n",
    "# each match has also a start and end\n",
    "# we just check which sentence has an end bigger than the match's start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    if found_matches[1][1] < sentence.end:\n",
    "        print(sentence)\n",
    "        break\n",
    "\n",
    "# the same, with the second match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}