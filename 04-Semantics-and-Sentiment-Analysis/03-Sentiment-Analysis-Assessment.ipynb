{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Assessment - Solution\n",
    "\n",
    "## Task #1: Perform vector arithmetic on your own words\n",
    "Write code that evaluates vector arithmetic on your own set of related words. The goal is to come as close to an expected word as possible. Please feel free to share success stories in the Q&A Forum for this section!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spaCy and load the language library. Remember to use a larger model!\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the words you wish to compare, and obtain their vectors\n",
    "fighter = nlp.vocab['fighter'].vector \n",
    "villain = nlp.vocab['villain'].vector \n",
    "hero = nlp.vocab['hero'].vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spatial and define a cosine_similarity function\n",
    "from scipy import spatial\n",
    "\n",
    "cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write an expression for vector arithmetic\n",
    "# For example: new_vector = word1 - word2 + word3\n",
    "new_vector = fighter - villain + hero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "new_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List the top ten closest vectors in the vocabulary to the result of the expression above\n",
    "\n",
    "computed_similarities = []\n",
    "\n",
    "for word in nlp.vocab:\n",
    "    if word.has_vector:\n",
    "        if word.is_lower:\n",
    "            if word.is_alpha:\n",
    "                similarity = cosine_similarity(new_vector, word.vector)\n",
    "                computed_similarities.append((word, similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(computed_similarities[0])\n",
    "\n",
    "# sorting by similarity\n",
    "computed_similarities = sorted(computed_similarities, key=lambda item:-item[1])\n",
    "\n",
    "[t[0].text for t in computed_similarities[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CHALLENGE: Write a function that takes in 3 strings, performs a-b+c arithmetic, and returns a top-ten result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_math(a,b,c):\n",
    "    word1 = nlp.vocab[a].vector\n",
    "    word2 = nlp.vocab[b].vector\n",
    "    word3 = nlp.vocab[c].vector\n",
    "\n",
    "    new_vector = word1 + word2 - word3\n",
    "    computed_similarities = []\n",
    "\n",
    "    for word in nlp.vocab:\n",
    "        if word.has_vector:\n",
    "            if word.is_lower:\n",
    "                if word.is_alpha:\n",
    "                    similarity = cosine_similarity(new_vector, word.vector)\n",
    "                    computed_similarities.append((word, similarity))\n",
    "    \n",
    "    # sort\n",
    "    computed_similarities = sorted(computed_similarities, key=lambda item: -item[1])\n",
    "\n",
    "    return [t[0].text for t in computed_similarities[:10]]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['king',\n",
       " 'kings',\n",
       " 'lord',\n",
       " 'prince',\n",
       " 'kingdom',\n",
       " 'throne',\n",
       " 'reign',\n",
       " 'mighty',\n",
       " 'princes',\n",
       " 'emperor']"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "# Test the function on known words:\n",
    "vector_math('king','man','woman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task #2: Perform VADER Sentiment Analysis on your own review\n",
    "Write code that returns a set of SentimentIntensityAnalyzer polarity scores based on your own written review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /Users/amescua/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "# Import SentimentIntensityAnalyzer and create an sid object\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('vader_lexicon') # if you downloaded vader already you can skip this\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a review as one continuous string (multiple sentences are ok)\n",
    "review = 'I really like this course of NLP!!. Is super cool, the content is very well explained.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.479, 'pos': 0.521, 'compound': 0.8994}"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "# Obtain the sid scores for your review\n",
    "sid.polarity_scores(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHALLENGE: Write a function that takes in a review and returns a score of \"Positive\", \"Negative\" or \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_rating(string):\n",
    "    get_value = lambda score: 'Positive' if score['compound'] > 0 else 'Negative' if score['compound'] < 0 else 'Neutral'\n",
    "\n",
    "    return get_value(sid.polarity_scores(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'POS'"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "# Test the function on your review above:\n",
    "review_rating(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}