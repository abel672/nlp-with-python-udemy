{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    with open(filepath) as f:\n",
    "        str_text = f.read()\n",
    "    \n",
    "    return str_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_file('moby_dick_four_chapters.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.max_length = 1198623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_punc(doc_text):\n",
    "    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = read_file('moby_dick_four_chapters.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = separate_punc(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11338"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "len(tokens) # words here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#25 words --> network predicts word #26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 25 + 1\n",
    "\n",
    "text_sequences = []\n",
    "\n",
    "for i in range(train_len, len(tokens)):\n",
    "    seq = tokens[i-train_len:i]\n",
    "\n",
    "    text_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "type(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on'"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "# text_sequences[0]\n",
    "# text_sequences[1] # sequences, each sequence is one token over (+1 beginign and end)\n",
    "\n",
    "' '.join(text_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore'"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "' '.join(text_sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore i'"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "' '.join(text_sequences[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format text sequence into a numerical sequence for keras\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have our converted numeric sequences\n",
    "# sequences[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each number is actually a word (token)\n",
    "# tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "956 : call\n14 : me\n263 : ishmael\n51 : some\n261 : years\n408 : ago\n87 : never\n219 : mind\n129 : how\n111 : long\n954 : precisely\n260 : having\n50 : little\n43 : or\n38 : no\n315 : money\n7 : in\n23 : my\n546 : purse\n3 : and\n150 : nothing\n259 : particular\n6 : to\n2712 : interest\n14 : me\n24 : on\n"
     ]
    }
   ],
   "source": [
    "for i in sequences[0]:\n",
    "    print(f\"{i} : {tokenizer.index_word[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how many times words appears in our sequence\n",
    "# tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(tokenizer.word_counts) # number of unique words in all this 4 chapters document that we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "type(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the sequence into a numpy matrix format, to create a train split with it\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 956,   14,  263, ..., 2712,   14,   24],\n",
       "       [  14,  263,   51, ...,   14,   24,  957],\n",
       "       [ 263,   51,  261, ...,   24,  957,    5],\n",
       "       ...,\n",
       "       [ 952,   12,  166, ...,  262,   53,    2],\n",
       "       [  12,  166, 2711, ...,   53,    2, 2717],\n",
       "       [ 166, 2711,    3, ...,    2, 2717,   26]])"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 2: Create our data (X, y)\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 956,   14,  263, ...,    6, 2712,   14],\n",
       "       [  14,  263,   51, ..., 2712,   14,   24],\n",
       "       [ 263,   51,  261, ...,   14,   24,  957],\n",
       "       ...,\n",
       "       [ 952,   12,  166, ...,   11,  262,   53],\n",
       "       [  12,  166, 2711, ...,  262,   53,    2],\n",
       "       [ 166, 2711,    3, ...,   53,    2, 2717]])"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "sequences[:, :-1] # each row of words (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  24,  957,    5, ...,    2, 2717,   26])"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "sequences[:,-1] # last word of each row (label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequences[:, :-1] # features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sequences[:,-1] # label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=vocabulary_size+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(11312, 25)"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "X.shape # (sequences, words per sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our model with the data\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding # LSTM: For the sequences, Embedding: for the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create models\n",
    "def create_model(vocabulary_size, seq_len):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(vocabulary_size, seq_len, input_length=seq_len))\n",
    "    # LSTM layer chooses amount of neurons, recommended to have as amount a multiple of seq_len\n",
    "    model.add(LSTM(seq_len*2, return_sequences=True)) # first param should be multiple of seq_len (Recomended)\n",
    "    model.add(LSTM(seq_len*2))\n",
    "\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(vocabulary_size, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 25, 25)            67950     \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 25, 50)            15200     \n_________________________________________________________________\nlstm_3 (LSTM)                (None, 50)                20200     \n_________________________________________________________________\ndense_2 (Dense)              (None, 50)                2550      \n_________________________________________________________________\ndense_3 (Dense)              (None, 2718)              138618    \n=================================================================\nTotal params: 244,518\nTrainable params: 244,518\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocabulary_size+1, seq_len) # creating our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save files for later and load them\n",
    "from pickle import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "89/89 [==============================] - 6s 39ms/step - loss: 7.4443 - accuracy: 0.0360\n",
      "Epoch 2/2\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 6.3543 - accuracy: 0.0521\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x654809d90>"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "model.fit(\n",
    "    X, y,\n",
    "    batch_size=128, # how many sequences do you want to pass at a time\n",
    "    epochs=2, # number of tranings in the execution\n",
    "    verbose=1 # output report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving our model\n",
    "model.save('my_mobydick_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer from Keras with all the vocabsulary of the documents\n",
    "dump(tokenizer,open('my_simpletokenizer','wb')) # saving our token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 3: Generate the next sequence of words by predictions\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "\n",
    "    output_text = []\n",
    "\n",
    "    input_text = seed_text\n",
    "\n",
    "    for i in range(num_gen_words):\n",
    "\n",
    "        # take input text and encode it to be a sequence\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0] \n",
    "\n",
    "        # pad the text: in case that is too long or too short, we adapt it   \n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "\n",
    "        #  predict the class probabilities for each word\n",
    "        # this method will throw the entire vocabulary and asign a probability to the most likely next word\n",
    "        pred_word_ind = model.predict_classes(pad_encoded, verbose=0)[0]\n",
    "  \n",
    "        # get the actual matched word\n",
    "        pred_word = tokenizer.index_word[pred_word_ind]\n",
    "\n",
    "        # add the predicted word in the original input text\n",
    "        input_text += ' '+pred_word\n",
    "\n",
    "        # adding the predicted word into the list\n",
    "        output_text.append(pred_word)\n",
    "    \n",
    "    # return all the predicted words\n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(101)\n",
    "random_pick = random.randint(0, len(text_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed_text = text_sequences[random_pick]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['thought',\n",
       " 'i',\n",
       " 'to',\n",
       " 'myself',\n",
       " 'the',\n",
       " 'man',\n",
       " \"'s\",\n",
       " 'a',\n",
       " 'human',\n",
       " 'being',\n",
       " 'just',\n",
       " 'as',\n",
       " 'i',\n",
       " 'am',\n",
       " 'he',\n",
       " 'has',\n",
       " 'just',\n",
       " 'as',\n",
       " 'much',\n",
       " 'reason',\n",
       " 'to',\n",
       " 'fear',\n",
       " 'me',\n",
       " 'as',\n",
       " 'i',\n",
       " 'have']"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "random_seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = ' '.join(random_seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"thought i to myself the man 's a human being just as i am he has just as much reason to fear me as i have\""
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'the the the the the the the the the the the the the the the the the the the the the the the the the'"
      ]
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "generate_text(model, tokenizer, seq_len, seed_text, num_gen_words=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load example model with 60% accuracy\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('epochBIG.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load(open('epochBIG', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"to be seen there was no bad olfactories my own letter was cheerily listening over his hearers who 's more can go have a wearing\""
      ]
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "source": [
    "generate_text(model, tokenizer, seq_len, seed_text, num_gen_words=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}